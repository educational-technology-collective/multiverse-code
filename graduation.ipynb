{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8428340f-e344-4c55-8ec0-9fadea4e95fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from fairlearn.metrics import MetricFrame, equalized_odds_difference\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from joblib import Parallel, delayed\n",
    "from jupyter_server.services.config import ConfigManager\n",
    "import os\n",
    "\n",
    "cm = ConfigManager()\n",
    "cm.update('notebook', {\"ServerApp.iopub_msg_rate_limit\": 100000})\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "%run helper.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd39a26e-e255-4055-a941-f5bed94c75a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16b39130-086d-4959-a322-4aab061bd702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x, y = premature(add_features_df, term_info_df, False)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3febdd1b-c12c-4a36-964e-786a6d6800a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features_df = pd.read_csv(\"add_features.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf41204-50a3-4ba0-9640-162e5fd488e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graduation_multiverse_col_names = [\"Include_Transfer\", \"Include_Sex\", \"Include_Race\",  \"Train_Size\", \"Handle_Nan\", \n",
    "#                                \"Scaler\", \"Encoder\", \"Sampler\", \"Classifier\", \"N_Estimators\", \"Learning_Rate\", \"C\", \"AUC_Graduated_In_4\", \n",
    "#                                 \"AUC_Graduated_In_6\", \"Equalized_Odds_Difference_Sex_4\", \"Equalized_Odds_Difference_Race_4\", \"Equalized_Odds_Difference_FG_4\", \"Equalized_Odds_Difference_Income_4\",  \"Equalized_Odds_Difference_Sex/Race_4\", \"Equalized_Odds_Difference_FG/Income_4\",\n",
    "#                                  \"Equalized_Odds_Difference_Sex_6\", \"Equalized_Odds_Difference_Race_6\", \"Equalized_Odds_Difference_FG_6\", \"Equalized_Odds_Difference_Income_6\", \"Equalized_Odds_Difference_Sex/Race_6\",\n",
    "#                                 \"Equalized_Odds_Difference_FG/Income_6\"]\n",
    "# graduation_multiverse_df = pd.DataFrame(columns=reenroll_multiverse_col_names)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b02ec775-f872-48b8-bfcb-f52584ff377b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graduation_multiverse_col_names = [\"Include_Transfer\", \"Include_Sex\", \"Include_Race\",  \"Train_Size\", \"Handle_Nan\", \n",
    "                               \"Scaler\", \"Encoder\", \"Sampler\", \"Classifier\", \"N_Estimators\", \"Learning_Rate\", \"C\", \"AUC_Graduated_In_4\", \n",
    "                                \"AUC_Graduated_In_6\", \"Equalized_Odds_Difference_Sex_4\", \"Equalized_Odds_Difference_Race_4\", \"Equalized_Odds_Difference_FG_4\", \"Equalized_Odds_Difference_Income_4\",  \"Equalized_Odds_Difference_Sex/Race_4\", \"Equalized_Odds_Difference_FG/Income_4\",\n",
    "                                 \"Equalized_Odds_Difference_Sex_6\", \"Equalized_Odds_Difference_Race_6\", \"Equalized_Odds_Difference_FG_6\", \"Equalized_Odds_Difference_Income_6\", \"Equalized_Odds_Difference_Sex/Race_6\",\n",
    "                                \"Equalized_Odds_Difference_FG/Income_6\"]\n",
    "feature_columns = ['STDNT_INTL_IND', 'STDNT_NTV_ENG_SPKR_IND', 'FIRST_US_PRMNNT_RES_PSTL_5_CD', 'PRNT_MAX_ED_LVL_DES', 'FIRST_TERM_ATTND_SHORT_DES',\n",
    "                      'STARTING_AGE', 'IS_FIRST_GEN', 'TRANSFER_CREDITS', 'MAX_SAT_SCR', 'EST_GROSS_FAM_INC_DES', 'Missing_Income', 'FIRST_YR_CUM_GPA', \n",
    "                      'FIRST_YR_TAKEN_CREDITS', 'HS_GPA', 'HS_CALC_IND', 'HS_CHEM_LAB_IND', 'PGM_1_MAJOR_1_CIP_DES', 'FIRST_UG_ENTRY_TYP_DES', 'STDNT_SEX_SHORT_DES',\n",
    "                  'STDNT_ETHNC_GRP_SHORT_DES', 'Sex/Race', 'FG/Income']\n",
    "\n",
    "# existing_df = pd.read_csv('partial_results.csv', low_memory=False)\n",
    "\n",
    "\n",
    "def process_grad_combination(include_transfer, handle_nan, train_size, include_sex, include_race, encoder, scaler, sampler, classifier, classifier_params):\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"Transformer\", 'passthrough'),\n",
    "        (\"Scaler\", 'passthrough'),\n",
    "        (\"Sampler\", 'passthrough'),\n",
    "        (\"Classifier\", 'passthrough')\n",
    "    ]) \n",
    "    \n",
    "    \n",
    "#     decision_df = pd.DataFrame([verse_dict])\n",
    "#     common_cols = decision_df.columns;\n",
    "#     # Function to compare rows with proper NaN handling\n",
    "#     def compare_rows(row1, row2):\n",
    "#         # Compare row1 and row2, treating NaNs as equal\n",
    "#         comparison = (row1 == row2) | ((row1.isna()) & (row2.isna()))\n",
    "#         return comparison.all()\n",
    "\n",
    "#     # Check each row in existing_df to see if it matches the current row in shit\n",
    "#     is_duplicate = existing_df[common_cols].apply(lambda row: compare_rows(row, decision_df.iloc[0][common_cols]), axis=1)\n",
    "\n",
    "#     if is_duplicate.any():\n",
    "#         print(\"Duplicate entry found, extracting and returning the existing result...\")\n",
    "#         duplicate_row = existing_df.loc[is_duplicate].iloc[0]\n",
    "#         # print(duplicate_row.to_dict())\n",
    "#         return duplicate_row.to_dict()\n",
    "\n",
    "    # Load and preprocess data\n",
    "    premature_X, premature_Y = graduation_premature(add_features_df, include_transfer=include_transfer)\n",
    "    features_df = premature_X[feature_columns].reset_index(drop=True)\n",
    "    premature_Y = premature_Y.reset_index(drop=True)\n",
    "    \n",
    "    if handle_nan == 'Drop':\n",
    "        rows_with_nan = features_df.isnull().any(axis=1)\n",
    "        X_after_nan = features_df[~rows_with_nan]\n",
    "        Y_after_nan = premature_Y[~rows_with_nan]\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_after_nan, Y_after_nan, train_size=train_size) # Train-Test Split\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        Y_train = Y_train.reset_index(drop=True)\n",
    "        Y_test = Y_test.reset_index(drop=True)\n",
    "        Y_train_4 = Y_train['GRADUATED_IN_4']\n",
    "        Y_train_6 = Y_train['GRADUATED_IN_6']\n",
    "\n",
    "        Y_test_4 = Y_test['GRADUATED_IN_4']\n",
    "        Y_test_6 = Y_test['GRADUATED_IN_6']\n",
    "    else:  \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(features_df, premature_Y, train_size=train_size) # Train - Test Split first\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        Y_train = Y_train.reset_index(drop=True)\n",
    "        Y_test = Y_test.reset_index(drop=True)\n",
    "        \n",
    "        Y_train_4 = Y_train['GRADUATED_IN_4']\n",
    "        Y_train_6 = Y_train['GRADUATED_IN_6']\n",
    "\n",
    "        Y_test_4 = Y_test['GRADUATED_IN_4']\n",
    "        Y_test_6 = Y_test['GRADUATED_IN_6']\n",
    "\n",
    "        # Perform imputation on the training data and apply it to the test data\n",
    "        imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "        X_train_array = imputer.fit_transform(X_train)\n",
    "        X_train = pd.DataFrame(X_train_array, columns=X_train.columns, index=X_train.index)\n",
    "\n",
    "        X_test_array = imputer.transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test_array, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "    sex_test = X_test['STDNT_SEX_SHORT_DES']\n",
    "    race_test = X_test['STDNT_ETHNC_GRP_SHORT_DES']\n",
    "    sex_race_test = X_test['Sex/Race']\n",
    "    fg_test = X_test['IS_FIRST_GEN']\n",
    "    income_test = X_test['EST_GROSS_FAM_INC_DES']\n",
    "    fg_income_test = X_test['FG/Income']\n",
    "    \n",
    "    X_train = X_train.drop(columns=['Sex/Race', 'FG/Income'])\n",
    "    X_test = X_test.drop(columns=['Sex/Race', 'FG/Income'])\n",
    "    \n",
    "    # Handle categorical features\n",
    "    if not include_sex:\n",
    "        X_train = X_train.drop(columns=['STDNT_SEX_SHORT_DES'])\n",
    "        X_test = X_test.drop(columns=['STDNT_SEX_SHORT_DES'])\n",
    "    if not include_race:\n",
    "        X_train = X_train.drop(columns=['STDNT_ETHNC_GRP_SHORT_DES'])\n",
    "        X_test = X_test.drop(columns=['STDNT_ETHNC_GRP_SHORT_DES'])\n",
    "\n",
    "    # Setup pipeline with caching\n",
    "    categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', encoder, categorical_columns)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    classifier.set_params(**classifier_params)\n",
    "    pipe.set_params(**{\n",
    "        \"Transformer\": preprocessor,\n",
    "        \"Scaler\": scaler,\n",
    "        \"Sampler\": sampler,\n",
    "        \"Classifier\": classifier\n",
    "    })\n",
    "\n",
    "\n",
    "    # Fit and evaluate\n",
    "    pipe.fit(X_train, Y_train_4)\n",
    "    y_pred_4 = pipe.predict(X_test)\n",
    "    y_prob_4 = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    auc_4 = roc_auc_score(Y_test_4, y_prob_4)\n",
    "    sex_eq_odds_diff_4 = equalized_odds_difference(Y_test_4, y_pred_4, sensitive_features=sex_test)\n",
    "    race_eq_odds_diff_4 = equalized_odds_difference(Y_test_4, y_pred_4, sensitive_features=race_test)\n",
    "    fg_eq_odds_diff_4 = equalized_odds_difference(Y_test_4, y_pred_4, sensitive_features=fg_test)\n",
    "    income_eq_odds_diff_4 = equalized_odds_difference(Y_test_4, y_pred_4, sensitive_features=income_test)\n",
    "    sex_race_eq_odds_diff_4 = equalized_odds_difference(Y_test_4, y_pred_4, sensitive_features=sex_race_test)\n",
    "    fg_income_eq_odds_diff_4 = equalized_odds_difference(Y_test_4, y_pred_4, sensitive_features=fg_income_test)\n",
    "    \n",
    "    # Fit and evaluate\n",
    "    pipe.fit(X_train, Y_train_6)\n",
    "    y_pred_6 = pipe.predict(X_test)\n",
    "    y_prob_6 = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    auc_6 = roc_auc_score(Y_test_6, y_prob_6)\n",
    "    sex_eq_odds_diff_6 = equalized_odds_difference(Y_test_6, y_pred_6, sensitive_features=sex_test)\n",
    "    race_eq_odds_diff_6 = equalized_odds_difference(Y_test_6, y_pred_6, sensitive_features=race_test)\n",
    "    fg_eq_odds_diff_6 = equalized_odds_difference(Y_test_6, y_pred_6, sensitive_features=fg_test)\n",
    "    income_eq_odds_diff_6 = equalized_odds_difference(Y_test_6, y_pred_6, sensitive_features=income_test)\n",
    "    sex_race_eq_odds_diff_6 = equalized_odds_difference(Y_test_6, y_pred_6, sensitive_features=sex_race_test)\n",
    "    fg_income_eq_odds_diff_6 = equalized_odds_difference(Y_test_6, y_pred_6, sensitive_features=fg_income_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    verse_dict = {\n",
    "    \"Include_Transfer\": 1 if include_transfer else 0,\n",
    "    \"Handle_Nan\": handle_nan,\n",
    "    \"Train_Size\": train_size,\n",
    "    \"Include_Sex\": 1 if include_sex else 0,\n",
    "    \"Include_Race\": 1 if include_race else 0,\n",
    "    \"Encoder\": 'OneHotEncoder' if isinstance(encoder, OneHotEncoder) else 'OrdinalEncoder',\n",
    "    \"Scaler\": 'StandardScaler' if scaler else None,\n",
    "    \"Sampler\": sampler.__class__.__name__ if sampler else None,\n",
    "    \"Classifier\": classifier.__class__.__name__,\n",
    "    }\n",
    "\n",
    "    if isinstance(classifier, RandomForestClassifier):\n",
    "        verse_dict['N_Estimators'] = classifier.n_estimators\n",
    "    elif isinstance(classifier, GradientBoostingClassifier):\n",
    "        verse_dict['Learning_Rate'] = classifier.learning_rate\n",
    "    elif isinstance(classifier, LogisticRegression):\n",
    "        verse_dict['C'] = classifier.C\n",
    "\n",
    "\n",
    "    # Add the AUC and equalized odds difference after classifier parameters\n",
    "    verse_dict.update({\n",
    "        \"AUC_Graduated_In_4\": auc_4,\n",
    "        \"Equalized_Odds_Difference_Sex_4\": sex_eq_odds_diff_4,\n",
    "        \"Equalized_Odds_Difference_Race_4\": race_eq_odds_diff_4,\n",
    "        \"Equalized_Odds_Difference_FG_4\": fg_eq_odds_diff_4,\n",
    "        \"Equalized_Odds_Difference_Income_4\": income_eq_odds_diff_4,\n",
    "        \"Equalized_Odds_Difference_Sex/Race_4\": sex_race_eq_odds_diff_4,\n",
    "        \"Equalized_Odds_Difference_FG/Income_4\": fg_income_eq_odds_diff_4,\n",
    "        \"AUC_Graduated_In_6\": auc_6,\n",
    "        \"Equalized_Odds_Difference_Sex_6\": sex_eq_odds_diff_6,\n",
    "        \"Equalized_Odds_Difference_Race_6\": race_eq_odds_diff_6,\n",
    "        \"Equalized_Odds_Difference_FG_6\": fg_eq_odds_diff_6,\n",
    "        \"Equalized_Odds_Difference_Income_6\": income_eq_odds_diff_6,\n",
    "        \"Equalized_Odds_Difference_Sex/Race_6\": sex_race_eq_odds_diff_6,\n",
    "        \"Equalized_Odds_Difference_FG/Income_6\": fg_income_eq_odds_diff_6\n",
    "    })\n",
    "    \n",
    "    # Ensure that the DataFrame has consistent columns\n",
    "    result_df = pd.DataFrame([verse_dict], columns=graduation_multiverse_col_names)\n",
    "    save_header = not os.path.isfile('graduation_partial_results.csv')\n",
    "\n",
    "    # Save the result after processing each combination\n",
    "    with open('graduation_partial_results.csv', 'a') as f:\n",
    "        result_df.to_csv(f, header=save_header, index=False)\n",
    "    return verse_dict\n",
    "\n",
    "# Parallel execution\n",
    "results = Parallel(n_jobs=-1, backend=\"multiprocessing\")(\n",
    "    delayed(process_grad_combination)(\n",
    "        include_transfer, handle_nan, train_size, include_sex, include_race, encoder, scaler, sampler, classifier, classifier_params\n",
    "    )\n",
    "   for include_transfer in [True, False]\n",
    "    for handle_nan in [\"Impute\", \"Drop\"]\n",
    "    for train_size in [0.7, 0.8]\n",
    "    for include_sex in [True, False]\n",
    "    for include_race in [True, False]\n",
    "    for encoder in [OneHotEncoder(handle_unknown='ignore'), OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)]\n",
    "    for scaler in [StandardScaler(with_mean=False), None]\n",
    "    for sampler in [SMOTE(), NearMiss(), None]\n",
    "    for classifier, classifier_params in [\n",
    "        (RandomForestClassifier(), {\"n_estimators\": 50}),\n",
    "        (RandomForestClassifier(), {\"n_estimators\": 100}),\n",
    "        (RandomForestClassifier(), {\"n_estimators\": 150}),\n",
    "        (GradientBoostingClassifier(), {\"learning_rate\": 0.01}),\n",
    "        (GradientBoostingClassifier(), {\"learning_rate\": 0.1}),\n",
    "        (GradientBoostingClassifier(), {\"learning_rate\": 1}),\n",
    "        (LogisticRegression(max_iter=3500, solver='saga'), {\"C\": 0.01}),\n",
    "        (LogisticRegression(max_iter=3500, solver='saga'), {\"C\": 0.1}),\n",
    "        (LogisticRegression(max_iter=3500, solver='saga'), {\"C\": 1})\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convert results to DataFrame and save to CSV\n",
    "graduation_multiverse_df = pd.DataFrame(results)\n",
    "graduation_multiverse_df.to_csv(\"graduation_multiverse_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "210249da-77ff-49cd-bc85-b796eae1320d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grad_df = pd.read_csv('graduation_multiverse_result.csv', low_memory=False)\n",
    "# grad_df = grad_df.round(3)\n",
    "# grad_df.to_csv('graduation_multiverse.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a24a8c20-a0b8-4f51-b294-e5a11de2daa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# existing_df = pd.read_csv('partial_results.csv', low_memory=False)\n",
    "# verse_dict = {\n",
    "#     \"Include_Transfer\": 1,\n",
    "#     \"Handle_Nan\": 'Impute',\n",
    "#     \"Train_Size\": 0.7,\n",
    "#     \"Include_Sex\": 1, \n",
    "#     \"Include_Race\": 1,\n",
    "#     \"Encoder\": 'OneHotEncoder', \n",
    "#     \"Scaler\":  None,\n",
    "#     \"Sampler\": None,\n",
    "#     \"Classifier\": 'LogisticRegression',\n",
    "#     'C': 1\n",
    "#     }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modules",
   "language": "python",
   "name": "haytham"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
